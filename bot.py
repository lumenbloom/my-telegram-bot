# bot.py
import os
from collections import defaultdict
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)
from openai import AsyncOpenAI
from fastapi import FastAPI, Request
from fastapi.responses import PlainTextResponse
from contextlib import asynccontextmanager
import httpx

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç¯å¢ƒå˜é‡é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_TOKEN = os.environ["TELEGRAM_TOKEN"]
LLM_API_KEY    = os.environ["LLM_API_KEY"]
LLM_BASE_URL   = os.environ.get("LLM_BASE_URL", "https://api.deepseek.com/v1")
MODEL_NAME     = os.environ.get("MODEL_NAME", "deepseek-chat")
BOT_PERSONALITY = os.environ.get("BOT_PERSONALITY", "ä½ æ˜¯ä¸€ä¸ªèªæ˜åˆæœ‰è¶£çš„åŠ©æ‰‹ï¼Œè¯·è¯´ä¸­æ–‡ã€‚")

# ğŸ›ï¸ æ–°å¢ï¼šåŸºäº token çš„ä¸Šä¸‹æ–‡æ§åˆ¶
MAX_CONTEXT_TOKENS = int(os.environ.get("MAX_CONTEXT_TOKENS", "8000"))  # é»˜è®¤8000 tokens
LLM_TEMPERATURE    = float(os.environ.get("LLM_TEMPERATURE", "0.7"))
LLM_MAX_TOKENS     = int(os.environ.get("LLM_MAX_TOKENS", "2000"))

PORT               = int(os.environ.get("PORT", 10000))
WEBHOOK_PATH       = "/webhook"
RENDER_EXTERNAL_HOSTNAME = os.environ["RENDER_EXTERNAL_HOSTNAME"]
WEBHOOK_URL        = f"https://{RENDER_EXTERNAL_HOSTNAME}{WEBHOOK_PATH}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_history = defaultdict(list)
client = AsyncOpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL, timeout=60.0)
tg_app = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç®€å•çš„ token ä¼°ç®—å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def estimate_tokens(messages):
    """ä¼°ç®—æ¶ˆæ¯åˆ—è¡¨çš„ token æ•°ï¼ˆç®€å•æŒ‰å­—ç¬¦ä¼°ç®—ï¼‰"""
    text = "".join([msg["content"] for msg in messages])
    # ç²—ç•¥ä¼°ç®—ï¼š1ä¸ª token â‰ˆ 4ä¸ªä¸­æ–‡å­—ç¬¦ æˆ– 1ä¸ªè‹±æ–‡å•è¯
    # è¿™é‡ŒæŒ‰ 1 token = 1.5 å­—ç¬¦ æ¥ä¼°ç®—ï¼Œä½ å¯ä»¥æ ¹æ®æ¨¡å‹è°ƒæ•´
    return len(text) // 1.5

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ä½ å¥½ï¼æˆ‘æ˜¯ç”±å¤§æ¨¡å‹é©±åŠ¨çš„æœºå™¨äººï¼Œéšä¾¿èŠï½")

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_history[user_id].clear()
    await update.message.reply_text("âœ… å·²é‡ç½®å¯¹è¯å†å²")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()
    if not text: return

    history = user_history[user_id]
    history.append({"role": "user", "content": text})
    
    # ğŸ” æ§åˆ¶å†å²ä¸Šä¸‹æ–‡ token é•¿åº¦
    while True:
        system_msg = {"role": "system", "content": BOT_PERSONALITY}
        full_context = [system_msg] + history
        tokens = estimate_tokens(full_context)
        
        if tokens <= MAX_CONTEXT_TOKENS:
            messages = full_context
            break
        elif len(history) > 1:
            # ç§»é™¤æœ€æ—©çš„ä¸€æ¡ç”¨æˆ·+åŠ©æ‰‹å¯¹è¯
            if len(history) >= 2 and history[0]["role"] == "user" and history[1]["role"] == "assistant":
                history = history[2:]
            else:
                history = history[1:]
        else:
            # å¦‚æœåªå‰©ä¸‹ä¸€æ¡æ¶ˆæ¯è¿˜è¶…é•¿ï¼Œæˆªæ–­å®ƒ
            history[-1]["content"] = history[-1]["content"][-1000:]  # ä¿ç•™æœ€å1000å­—ç¬¦
            break

    reply = await ask_llm(messages)
    history.append({"role": "assistant", "content": reply})

    # ğŸ“ åˆ†æ®µå‘é€é•¿æ¶ˆæ¯
    for i in range(0, len(reply), 4000):
        await update.message.reply_text(reply[i:i+4000])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è°ƒç”¨ LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def ask_llm(messages):
    try:
        resp = await client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=LLM_TEMPERATURE,
            max_tokens=LLM_MAX_TOKENS,
            stream=False
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"æŠ±æ­‰ï¼Œå¤§æ¨¡å‹å‡ºé”™äº†ï¼š{str(e)[:200]}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆå§‹åŒ– Telegram Bot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def init():
    global tg_app
    tg_app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    tg_app.add_handler(CommandHandler("start", start))
    tg_app.add_handler(CommandHandler("reset", reset))
    tg_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    await tg_app.initialize()
    await tg_app.bot.set_webhook(WEBHOOK_URL)
    print(f"âœ… Webhook set to: {WEBHOOK_URL}")
    print(f"ğŸ”§ é…ç½®: æœ€å¤§ä¸Šä¸‹æ–‡={MAX_CONTEXT_TOKENS} tokens, æ¸©åº¦={LLM_TEMPERATURE}, æœ€å¤§è¾“å‡º={LLM_MAX_TOKENS}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI APP Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@asynccontextmanager
async def lifespan(app: FastAPI):
    await init()
    yield

app = FastAPI(lifespan=lifespan)

@app.post(WEBHOOK_PATH)
async def webhook(request: Request):
    json_data = await request.json()
    update = Update.de_json(json_data, tg_app.bot)
    await tg_app.process_update(update)
    return PlainTextResponse("OK")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main Entry Point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    print(f"ğŸš€ Starting bot on port {PORT}...")
    uvicorn.run(app, host="0.0.0.0", port=PORT)