# æ–‡ä»¶å: bot.py
# Python 3.10+
# åŠŸèƒ½ï¼š
# - ä½¿ç”¨ LLM API è‡ªç”±å¯¹è¯
# - æ”¯æŒè‡ªå®šä¹‰ system prompt
# - æ”¯æŒ Webhook æ¨¡å¼éƒ¨ç½²åˆ° Render

import os
import asyncio
from collections import defaultdict

from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)
from openai import AsyncOpenAI

# ---------------------------- é…ç½®åŒº -------------------------------
TELEGRAM_TOKEN = os.environ["TELEGRAM_TOKEN"]     # è®¾ç½®åœ¨ Render ç¯å¢ƒå˜é‡ä¸­
LLM_API_KEY    = os.environ["LLM_API_KEY"]
LLM_BASE_URL   = os.environ.get("LLM_BASE_URL", "https://api.deepseek.com/v1")
MODEL_NAME     = os.environ.get("MODEL_NAME", "deepseek-chat")
BOT_PERSONALITY = os.environ.get("BOT_PERSONALITY", "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜ã€èªæ˜ã€æœ‰ç‚¹æ¯’èˆŒçš„åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚")
PORT           = int(os.environ.get("PORT", 8080))  # Render é»˜è®¤ç«¯å£éœ€æ˜¯ 10000ï¼Œä½†æŸäº›æœåŠ¡å…è®¸ 8080

WEBHOOK_PATH = "/webhook"
RENDER_EXTERNAL_HOSTNAME = os.environ.get("RENDER_EXTERNAL_HOSTNAME")
WEBHOOK_URL = f"https://{RENDER_EXTERNAL_HOSTNAME}{WEBHOOK_PATH}"

# ---------------------------- åˆå§‹åŒ–å…¨å±€å¯¹è±¡ -----------------------
user_history = defaultdict(list)
client = AsyncOpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL, timeout=90.0)

# ---------------------------- Telegram Handlers ---------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ä½ å¥½ï¼æˆ‘æ˜¯ç”±å¤§æ¨¡å‹é©±åŠ¨çš„æœºå™¨äººï¼Œéšä¾¿èŠï½")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()

    if not text:
        return

    history = user_history[user_id]
    history.append({"role": "user", "content": text})

    if len(history) > 24:
        history = history[-24:]

    messages = [
        {"role": "system", "content": BOT_PERSONALITY}
    ] + history

    reply = await ask_llm(messages)

    history.append({"role": "assistant", "content": reply})

    if len(reply) > 4000:
        for i in range(0, len(reply), 4000):
            await update.message.reply_text(reply[i:i + 4000])
    else:
        await update.message.reply_text(reply)

# ---------------------------- LLM æ¥å£è°ƒç”¨ ----------------------------
async def ask_llm(messages):
    try:
        resp = await client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            temperature=0.7,
            max_tokens=4000,
            stream=False
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"æŠ±æ­‰ï¼Œå¤§æ¨¡å‹å‡ºé”™äº†ï¼š{str(e)[:200]}"

# ------------------------------- ä¸»ç¨‹åºå…¥å£ï¼ˆwebhook å¯åŠ¨ï¼‰------------------
from fastapi import FastAPI, Request
from fastapi.responses import PlainTextResponse

app = FastAPI()

# FastAPI è·¯ç”±å¤„ç† Telegram Webhook
@app.post(WEBHOOK_PATH)
async def webhook(request: Request):
    json_data = await request.json()
    update = Update.de_json(json_data, tg_app.bot)
    await tg_app.process_update(update)
    return PlainTextResponse("OK")

# å¼‚æ­¥åˆå§‹åŒ–å‡½æ•°
async def init():
    global tg_app
    tg_app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    tg_app.add_handler(CommandHandler("start", start))
    tg_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    await tg_app.initialize()
    await tg_app.bot.set_webhook(WEBHOOK_URL)
    print(f"âœ… Webhook å·²è®¾ç½®ä¸º: {WEBHOOK_URL}")

# å¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œ init å‡½æ•°
@app.on_event("startup")
async def startup_event():
    await init()

# ------------------------------- ç¨‹åºå…¥å£ -------------------------------
if __name__ == "__main__":
    import uvicorn
    print(f"ğŸš€ æ­£åœ¨å¯åŠ¨ bot on port {PORT}...")
    uvicorn.run(app, host="0.0.0.0", port=PORT)